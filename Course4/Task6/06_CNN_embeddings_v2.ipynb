{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/Amikuto/DAaML/blob/master/06_CNN_embeddings_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn"
   ],
   "metadata": {
    "id": "rzp4sZEXvqbu"
   },
   "execution_count": 349,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ubw-7tnMq_2O"
   },
   "source": [
    "# 6. Классификация текстов при помощи сверточных сетей\n",
    "\n",
    "__Автор__: Никита Владимирович Блохин (NVBlokhin@fa.ru)\n",
    "\n",
    "Финансовый университет, 2020 г. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tx75RigN8xIJ"
   },
   "source": [
    "## 1. Представление и предобработка текстовых данных в виде последовательностей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LScKIAey9dAM"
   },
   "source": [
    "1.1 Представьте первое предложение из строки `text` как последовательность из индексов слов, входящих в это предложение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "id": "phEw721T9SYW"
   },
   "outputs": [],
   "source": [
    "text = 'Select your preferences and run the install command. Stable represents the most currently tested and supported version of PyTorch. Note that LibTorch is only available for C++'"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "first_sen = nltk.sent_tokenize(text)[0].replace(\".\", \"\").lower()\n",
    "first_sen"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "hyfe6r9msENr",
    "outputId": "22f7b89e-910f-4603-f6f2-9215468a81c8"
   },
   "execution_count": 351,
   "outputs": [
    {
     "data": {
      "text/plain": "'select your preferences and run the install command'"
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "words = nltk.word_tokenize(first_sen)\n",
    "words"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AgvdsqF0rEWi",
    "outputId": "5d57b628-0bae-47cf-b215-8be35ea39eb7"
   },
   "execution_count": 352,
   "outputs": [
    {
     "data": {
      "text/plain": "['select', 'your', 'preferences', 'and', 'run', 'the', 'install', 'command']"
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "words_dict = {k: v for v, k in enumerate(words)}\n",
    "words_dict"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZK1iUyWJrEhC",
    "outputId": "70a5ddaf-27bd-433b-9e47-2fd9fdbab494"
   },
   "execution_count": 353,
   "outputs": [
    {
     "data": {
      "text/plain": "{'select': 0,\n 'your': 1,\n 'preferences': 2,\n 'and': 3,\n 'run': 4,\n 'the': 5,\n 'install': 6,\n 'command': 7}"
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "[words_dict[i] for i in words]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_HYpfPZ2rEoq",
    "outputId": "1afe4e36-a569-4e17-fc5e-0747da414078"
   },
   "execution_count": 354,
   "outputs": [
    {
     "data": {
      "text/plain": "[0, 1, 2, 3, 4, 5, 6, 7]"
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSFQCPtD9x5J"
   },
   "source": [
    "1.2 Представьте первое предложение из строки `text` как последовательность векторов, соответствующих индексам слов. Для представления индекса в виде вектора используйте унитарное кодирование. В результате должен получиться двумерный тензор размера `количество слов в предложении` x `количество уникальных слов`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "id": "RZS4XLV0-buf"
   },
   "outputs": [],
   "source": [
    "text = 'Select your preferences and run the install command. Stable represents the most currently tested and supported version of PyTorch. Note that LibTorch is only available for C++'"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "all_words = nltk.word_tokenize(text.lower().replace(\".\", \"\"))\n",
    "all_words_dict = {k: v for v, k in enumerate(all_words)}\n",
    "all_words_dict"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Da6RwV5Ft8vl",
    "outputId": "11f25514-927b-4698-e883-48d9eb603c09"
   },
   "execution_count": 356,
   "outputs": [
    {
     "data": {
      "text/plain": "{'select': 0,\n 'your': 1,\n 'preferences': 2,\n 'and': 14,\n 'run': 4,\n 'the': 10,\n 'install': 6,\n 'command': 7,\n 'stable': 8,\n 'represents': 9,\n 'most': 11,\n 'currently': 12,\n 'tested': 13,\n 'supported': 15,\n 'version': 16,\n 'of': 17,\n 'pytorch': 18,\n 'note': 19,\n 'that': 20,\n 'libtorch': 21,\n 'is': 22,\n 'only': 23,\n 'available': 24,\n 'for': 25,\n 'c++': 26}"
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "first_sen = nltk.sent_tokenize(text)[0].replace(\".\", \"\").lower()\n",
    "first_sen_words = nltk.word_tokenize(first_sen)\n",
    "first_sen_words"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wLdymMdHt9CM",
    "outputId": "6f6127c8-02c2-4bda-aba3-347d832631a0"
   },
   "execution_count": 357,
   "outputs": [
    {
     "data": {
      "text/plain": "['select', 'your', 'preferences', 'and', 'run', 'the', 'install', 'command']"
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tensor = torch.zeros(len(first_sen_words), len(all_words_dict))"
   ],
   "metadata": {
    "id": "6XzpTKflt9Wk"
   },
   "execution_count": 358,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i, word in enumerate(first_sen_words):\n",
    "  tensor[i][all_words_dict[word]] = 1\n",
    "  print(all_words_dict[word])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OiGYhp0Yt9ca",
    "outputId": "8d21b7c9-2d23-4fa8-b467-d75a8a9dbc16"
   },
   "execution_count": 359,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "14\n",
      "4\n",
      "10\n",
      "6\n",
      "7\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tensor"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMnPjWx8t9jq",
    "outputId": "4d33702b-bfd9-4c2e-ce53-63fcaf69e79a"
   },
   "execution_count": 360,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0.]])"
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([8, 25])"
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZvQKHYA-mJN"
   },
   "source": [
    "1.3 Решите задачу 1.2, используя модуль `nn.Embedding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "outputs": [
    {
     "data": {
      "text/plain": "25"
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocab = Counter(all_words_dict)\n",
    "vocab = sorted(vocab, key=vocab.get, reverse=True)\n",
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "outputs": [
    {
     "data": {
      "text/plain": "{'c++': 0,\n 'for': 1,\n 'available': 2,\n 'only': 3,\n 'is': 4,\n 'libtorch': 5,\n 'that': 6,\n 'note': 7,\n 'pytorch': 8,\n 'of': 9,\n 'version': 10,\n 'supported': 11,\n 'and': 12,\n 'tested': 13,\n 'currently': 14,\n 'most': 15,\n 'the': 16,\n 'represents': 17,\n 'stable': 18,\n 'command': 19,\n 'install': 20,\n 'run': 21,\n 'preferences': 22,\n 'your': 23,\n 'select': 24}"
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx = {word: ind for ind, word in enumerate(vocab)}\n",
    "word2idx"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "outputs": [
    {
     "data": {
      "text/plain": "[24, 23, 22, 12, 21, 16, 20, 19]"
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_sentences = [word2idx[word] for word in first_sen_words]\n",
    "encoded_sentences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-9.8497e-01, -8.3152e-01, -1.5091e+00, -1.1183e+00,  5.6081e-02,\n         -7.6570e-01,  1.0942e+00,  6.2499e-01,  7.0286e-01, -2.7504e-01,\n          9.7120e-01, -5.0217e-01, -2.4522e-01,  1.0535e+00,  2.0797e+00,\n          4.4264e-01, -1.2697e+00,  7.3438e-01, -7.2332e-01,  1.0820e+00,\n         -2.4006e-01, -1.8046e+00,  9.3524e-01,  8.2588e-01, -5.5058e-01],\n        [-1.2424e+00, -1.1253e+00, -6.5582e-02,  2.2343e-01,  1.3020e+00,\n         -1.2041e+00,  2.4841e-01,  1.2204e-01,  1.0141e+00, -2.8781e-01,\n          1.5336e-02,  4.4684e-01,  3.6950e-01, -1.2953e+00, -5.6597e-02,\n          2.7682e-01, -4.4070e-01, -8.0875e-01, -9.1628e-01, -1.7093e+00,\n         -1.4255e-01,  1.0989e+00, -1.0450e+00,  1.0068e+00,  4.8541e-01],\n        [-4.4633e-02, -8.7612e-01, -2.3910e+00, -2.0590e-01,  7.9070e-01,\n         -6.6066e-01,  9.0151e-01,  3.5316e-01, -6.2291e-01,  7.4781e-01,\n          6.2062e-01,  2.3577e+00, -1.4266e-01,  5.8851e-02,  8.0076e-01,\n         -2.0228e+00,  6.5720e-01,  1.9822e-01,  4.9328e-01,  7.1910e-01,\n          1.2928e-01,  7.7549e-01,  4.2149e-01,  5.1975e-01, -1.3774e+00],\n        [ 4.1630e-02, -1.5365e+00, -5.0538e-02,  1.7936e-01, -9.8225e-01,\n          1.0253e-01,  1.0491e+00,  3.4502e-01,  6.9947e-01,  6.1118e-01,\n         -3.6525e-01,  3.7122e-02, -3.9628e-01, -5.7243e-01,  2.2324e-01,\n          1.1315e+00, -9.7711e-01,  8.0038e-01, -7.0374e-02, -1.0212e+00,\n         -5.5791e-01, -8.2838e-01,  7.3646e-01, -1.1610e-01, -1.1915e-01],\n        [ 1.9553e-01, -7.9344e-01,  6.0576e-01, -8.8896e-01, -1.6119e-01,\n          1.9014e-01, -4.4322e-01,  1.4309e+00, -2.5868e-01, -4.0361e-01,\n         -1.2229e+00,  4.2962e-01,  9.1908e-01, -3.1347e-01, -6.5581e-01,\n          1.0085e+00,  2.1496e-01, -1.0146e+00,  2.9509e-01, -6.6881e-01,\n          4.3929e-01, -1.4109e+00, -2.1297e+00, -4.1177e-01, -1.6138e+00],\n        [-6.1381e-01,  2.5916e-01, -3.5488e-02, -4.4760e-01, -6.9906e-01,\n         -3.0018e-01,  1.7266e+00,  2.9221e+00, -1.6335e+00,  5.5721e-01,\n          4.7084e-01, -4.5406e-01,  1.5841e-01,  9.7728e-01,  9.3605e-01,\n         -3.7470e-01, -9.0818e-01,  1.0637e+00,  3.0077e-01,  5.2112e-01,\n          6.1130e-01,  2.9245e-01, -3.8475e-01, -5.1408e-02, -9.4462e-01],\n        [ 1.6591e-01,  8.0796e-01, -1.4121e-01, -8.8527e-01, -1.8308e-03,\n          4.9149e-01,  1.8871e-01, -7.5466e-01, -2.3979e-01,  6.8478e-01,\n         -4.5494e-01, -1.3441e+00,  1.8233e-01, -2.3891e-01,  4.5974e-01,\n          1.7063e+00, -1.2798e-01,  4.1384e-01,  2.0244e-01,  1.1056e+00,\n         -1.6056e-01, -1.5298e-01,  1.0184e+00, -1.1562e-01,  3.3446e-02],\n        [ 5.2534e-01,  9.0478e-01, -7.3067e-01, -3.8412e-02, -3.2399e-01,\n         -2.9214e-01, -1.5055e+00,  1.1876e+00,  1.5280e+00,  6.9792e-02,\n          6.2260e-01, -6.1898e-02, -2.2350e-01, -4.1288e-01,  3.3433e-01,\n         -7.5643e-01,  1.7252e+00,  4.8945e-01,  1.0486e-02, -2.3042e-03,\n          1.0083e-01,  5.5113e-01,  9.8048e-01,  2.0121e-01,  8.0650e-01]],\n       grad_fn=<EmbeddingBackward0>)"
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dim = 25\n",
    "emb_layer = nn.Embedding(vocab_size, emb_dim)\n",
    "word_vectors = emb_layer(torch.LongTensor(encoded_sentences))\n",
    "word_vectors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([8, 25])"
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXjM7qEUNFY_"
   },
   "source": [
    "## 2. Классификация фамилий по национальности (ConvNet)\n",
    "\n",
    "Датасет: https://disk.yandex.ru/d/owHew8hzPc7X9Q?w=1\n",
    "\n",
    "2.1 Считать файл `surnames/surnames.csv`. \n",
    "\n",
    "2.2 Закодировать национальности числами, начиная с 0.\n",
    "\n",
    "2.3 Разбить датасет на обучающую и тестовую выборку\n",
    "\n",
    "2.4 Реализовать класс `Vocab` (токен = __символ__)\n",
    "  * добавьте в словарь специальный токен `<PAD>` с индексом 0\n",
    "  * при создании словаря сохраните длину самой длинной последовательности из набора данных в виде атрибута `max_seq_len`\n",
    "\n",
    "2.5 Реализовать класс `SurnamesDataset`\n",
    "  * метод `__getitem__` возвращает пару: <последовательность индексов токенов (см. 1.1 ), номер класса> \n",
    "  * длина каждой такой последовательности должна быть одинаковой и равной `vocab.max_seq_len`. Чтобы добиться этого, дополните последовательность справа индексом токена `<PAD>` до нужной длины\n",
    "\n",
    "2.6. Обучить классификатор.\n",
    "  \n",
    "  * Для преобразования последовательности индексов в последовательность векторов используйте `nn.Embedding`. Рассмотрите два варианта: \n",
    "    - когда токен представляется в виде унитарного вектора и модуль `nn.Embedding` не обучается\n",
    "    - когда токен представляется в виде вектора небольшой размерности (меньше, чем размер словаря) и модуль `nn.Embedding` обучается\n",
    "\n",
    "  * Используйте одномерные свертки и пулинг (`nn.Conv1d`, `nn.MaxPool1d`)\n",
    "    - обратите внимание, что `nn.Conv1d` ожидает на вход трехмерный тензор размерности `(batch, embedding_dim, seq_len)`\n",
    "\n",
    "2.7 Измерить точность на тестовой выборке. Проверить работоспособность модели: прогнать несколько фамилий студентов группы через модели и проверить результат. Для каждой фамилии выводить 3 наиболее вероятных предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "outputs": [
    {
     "data": {
      "text/plain": "    surname nationality\n0  Woodford     English\n1      Coté      French\n2      Kore     English\n3     Koury      Arabic\n4    Lebzak     Russian",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>surname</th>\n      <th>nationality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Woodford</td>\n      <td>English</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Coté</td>\n      <td>French</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Kore</td>\n      <td>English</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Koury</td>\n      <td>Arabic</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Lebzak</td>\n      <td>Russian</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surname_dataset = pd.read_csv(\"./surnames/surnames.csv\")\n",
    "surname_dataset.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "outputs": [
    {
     "data": {
      "text/plain": "{'English': 0,\n 'French': 1,\n 'Arabic': 2,\n 'Russian': 3,\n 'Japanese': 4,\n 'Chinese': 5,\n 'Italian': 6,\n 'Czech': 7,\n 'Irish': 8,\n 'German': 9,\n 'Greek': 10,\n 'Spanish': 11,\n 'Polish': 12,\n 'Dutch': 13,\n 'Vietnamese': 14,\n 'Korean': 15,\n 'Portuguese': 16,\n 'Scottish': 17}"
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surname_dict = pd.Series(surname_dataset.nationality.unique()).to_dict()\n",
    "surname_dict = dict(map(reversed, surname_dict.items()))\n",
    "surname_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "outputs": [
    {
     "data": {
      "text/plain": "        surname  nationality\n0      Woodford            0\n1          Coté            1\n2          Kore            0\n3         Koury            2\n4        Lebzak            3\n...         ...          ...\n10975  Quraishi            2\n10976   Innalls            0\n10977      Król           12\n10978    Purvis            0\n10979  Messerli            9\n\n[10980 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>surname</th>\n      <th>nationality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Woodford</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Coté</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Kore</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Koury</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Lebzak</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10975</th>\n      <td>Quraishi</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10976</th>\n      <td>Innalls</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10977</th>\n      <td>Król</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>10978</th>\n      <td>Purvis</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10979</th>\n      <td>Messerli</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n<p>10980 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_nation_as_index = surname_dataset.copy()\n",
    "dataset_nation_as_index.nationality = surname_dataset.nationality.map(lambda x: surname_dict[x])\n",
    "dataset_nation_as_index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset_nation_as_index[\"surname\"], dataset_nation_as_index[\"nationality\"], test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "outputs": [
    {
     "data": {
      "text/plain": "3163           Toma\n2232      Mokrinsky\n1150         Ohishi\n7923        Kumiega\n10284        Durnev\n            ...    \n8497        Krawiec\n453      Jachmenkov\n6166       Gasyukov\n5181      Ratcliffe\n7635       Reinders\nName: surname, Length: 8784, dtype: object"
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "outputs": [
    {
     "data": {
      "text/plain": "17"
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(X_train.map(len))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "outputs": [
    {
     "data": {
      "text/plain": "3163      2\n2232      3\n1150      4\n7923     12\n10284     3\n         ..\n8497      7\n453       3\n6166      3\n5181      0\n7635     13\nName: nationality, Length: 8784, dtype: int64"
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "id": "ZGfJX2NP1sw4"
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "  def __init__(self, column: pd.DataFrame | pd.Series):\n",
    "    all_chars = pd.Series(column.values).map(lambda x: list(x.lower())).explode().unique()\n",
    "    all_chars = np.insert(all_chars, 0, \"<PAD>\")\n",
    "    self.idx_to_token = {index: token for index, token in enumerate(all_chars)}\n",
    "    self.token_to_idx = {token: index for index, token in enumerate(all_chars)}\n",
    "    self.max_seq_len = max(column.map(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "outputs": [
    {
     "data": {
      "text/plain": "17"
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = Vocab(dataset_nation_as_index[\"surname\"])\n",
    "vocab.max_seq_len"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.5 Реализовать класс `SurnamesDataset`\n",
    "  * метод `__getitem__` возвращает пару: <последовательность индексов токенов (см. 1.1 ), номер класса>\n",
    "  * длина каждой такой последовательности должна быть одинаковой и равной `vocab.max_seq_len`. Чтобы добиться этого, дополните последовательность справа индексом токена `<PAD>` до нужной длины"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "id": "GHjCRqQg1sw5"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SurnamesDataset(Dataset):\n",
    "  def __init__(self, X, y, vocab: Vocab):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "    self.vocab = vocab\n",
    "    self.max_X = 17\n",
    "    self.max_y = 10\n",
    "\n",
    "  def vectorize(self, surename):\n",
    "    tensor = torch.zeros(self.vocab.max_seq_len, dtype=torch.long)\n",
    "    for i, val in enumerate(surename):\n",
    "      tensor[i] = self.vocab.token_to_idx[val.lower()]\n",
    "    tensor[tensor==0] = self.vocab.token_to_idx[\"<PAD>\"]\n",
    "    return tensor\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    surname = self.X.iloc[idx]\n",
    "\n",
    "    nation = self.y.iloc[idx]\n",
    "\n",
    "    return self.vectorize(surname).tolist(), nation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "outputs": [],
   "source": [
    "dataset = SurnamesDataset(X=X_train, y=y_train, vocab=vocab)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "outputs": [
    {
     "data": {
      "text/plain": "('Toma', 2)"
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0], y_train.iloc[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "outputs": [
    {
     "data": {
      "text/plain": "[7, 2, 20, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "2.6. Обучить классификатор.\n",
    "\n",
    "  * Для преобразования последовательности индексов в последовательность векторов используйте `nn.Embedding`. Рассмотрите два варианта:\n",
    "    - когда токен представляется в виде унитарного вектора и модуль `nn.Embedding` не обучается\n",
    "    - когда токен представляется в виде вектора небольшой размерности (меньше, чем размер словаря) и модуль `nn.Embedding` обучается\n",
    "\n",
    "  * Используйте одномерные свертки и пулинг (`nn.Conv1d`, `nn.MaxPool1d`)\n",
    "    - обратите внимание, что `nn.Conv1d` ожидает на вход трехмерный тензор размерности `(batch, embedding_dim, seq_len)`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.9094,  1.3261,  1.2423, -0.0236, -0.7022,  0.6126, -0.6979,  0.4125,\n         -0.5350, -0.0808, -0.3761, -1.1356,  0.7009, -0.6870,  0.6529,  0.4226,\n         -0.6821],\n        [-0.6040, -0.3058, -1.0245,  2.1413, -0.0207, -0.1976,  0.7568, -0.0139,\n         -0.0611, -1.3718,  2.1177,  1.4276,  1.3494,  0.4159,  1.5932, -0.2202,\n         -1.4642],\n        [ 0.4182,  0.5255,  0.3523,  1.2183,  0.9574, -1.4453,  0.0061,  1.6689,\n         -0.3007,  0.5705,  0.0977, -0.0649, -0.0423,  0.1966,  0.7472, -1.4083,\n         -0.4024],\n        [-0.2523, -0.0890,  0.9858,  1.1221,  0.3944,  1.0503, -1.5702, -1.6974,\n          1.6146, -2.1063, -1.7663, -0.6850,  0.3767,  0.5437, -0.5237,  1.1585,\n         -1.2444],\n        [-0.6220, -1.2674,  1.1593,  0.0367,  0.4477,  0.2179, -1.3347, -0.0228,\n         -0.5904, -0.9591, -1.1340,  1.9351, -0.0723, -0.6129,  0.1259, -0.2515,\n          0.7828],\n        [-0.6220, -1.2674,  1.1593,  0.0367,  0.4477,  0.2179, -1.3347, -0.0228,\n         -0.5904, -0.9591, -1.1340,  1.9351, -0.0723, -0.6129,  0.1259, -0.2515,\n          0.7828],\n        [-0.6220, -1.2674,  1.1593,  0.0367,  0.4477,  0.2179, -1.3347, -0.0228,\n         -0.5904, -0.9591, -1.1340,  1.9351, -0.0723, -0.6129,  0.1259, -0.2515,\n          0.7828],\n        [-0.6220, -1.2674,  1.1593,  0.0367,  0.4477,  0.2179, -1.3347, -0.0228,\n         -0.5904, -0.9591, -1.1340,  1.9351, -0.0723, -0.6129,  0.1259, -0.2515,\n          0.7828],\n        [-0.6220, -1.2674,  1.1593,  0.0367,  0.4477,  0.2179, -1.3347, -0.0228,\n         -0.5904, -0.9591, -1.1340,  1.9351, -0.0723, -0.6129,  0.1259, -0.2515,\n          0.7828],\n        [-0.6220, -1.2674,  1.1593,  0.0367,  0.4477,  0.2179, -1.3347, -0.0228,\n         -0.5904, -0.9591, -1.1340,  1.9351, -0.0723, -0.6129,  0.1259, -0.2515,\n          0.7828],\n        [-0.6220, -1.2674,  1.1593,  0.0367,  0.4477,  0.2179, -1.3347, -0.0228,\n         -0.5904, -0.9591, -1.1340,  1.9351, -0.0723, -0.6129,  0.1259, -0.2515,\n          0.7828],\n        [-0.6220, -1.2674,  1.1593,  0.0367,  0.4477,  0.2179, -1.3347, -0.0228,\n         -0.5904, -0.9591, -1.1340,  1.9351, -0.0723, -0.6129,  0.1259, -0.2515,\n          0.7828],\n        [-0.6220, -1.2674,  1.1593,  0.0367,  0.4477,  0.2179, -1.3347, -0.0228,\n         -0.5904, -0.9591, -1.1340,  1.9351, -0.0723, -0.6129,  0.1259, -0.2515,\n          0.7828],\n        [-0.6220, -1.2674,  1.1593,  0.0367,  0.4477,  0.2179, -1.3347, -0.0228,\n         -0.5904, -0.9591, -1.1340,  1.9351, -0.0723, -0.6129,  0.1259, -0.2515,\n          0.7828],\n        [-0.6220, -1.2674,  1.1593,  0.0367,  0.4477,  0.2179, -1.3347, -0.0228,\n         -0.5904, -0.9591, -1.1340,  1.9351, -0.0723, -0.6129,  0.1259, -0.2515,\n          0.7828],\n        [-0.6220, -1.2674,  1.1593,  0.0367,  0.4477,  0.2179, -1.3347, -0.0228,\n         -0.5904, -0.9591, -1.1340,  1.9351, -0.0723, -0.6129,  0.1259, -0.2515,\n          0.7828],\n        [-0.6220, -1.2674,  1.1593,  0.0367,  0.4477,  0.2179, -1.3347, -0.0228,\n         -0.5904, -0.9591, -1.1340,  1.9351, -0.0723, -0.6129,  0.1259, -0.2515,\n          0.7828]], grad_fn=<EmbeddingBackward0>)"
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = nn.Embedding(21, 17)\n",
    "w = l(torch.LongTensor(dataset[0][0]))\n",
    "w"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "outputs": [
    {
     "data": {
      "text/plain": "17"
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uo-hf5CQ0iWv"
   },
   "source": [
    "## 3. Классификация обзоров на фильмы (ConvNet)\n",
    "\n",
    "Датасет: https://disk.yandex.ru/d/tdinpb0nN_Dsrg\n",
    "\n",
    "2.1 Создайте набор данных на основе файлов polarity/positive_reviews.csv (положительные отзывы) и polarity/negative_reviews.csv (отрицательные отзывы). Разбейте на обучающую и тестовую выборку.\n",
    "  * токен = __слово__\n",
    "  * данные для обучения в датасете представляются в виде последовательности индексов токенов\n",
    "  * словарь создается на основе _только_ обучающей выборки. Для корректной обработки ситуаций, когда в тестовой выборке встретится токен, который не хранится в словаре, добавьте в словарь специальный токен `<UNK>`\n",
    "  * добавьте предобработку текста\n",
    "\n",
    "2.2. Обучите классификатор.\n",
    "  \n",
    "  * Для преобразования последовательности индексов в последовательность векторов используйте `nn.Embedding` \n",
    "    - подберите адекватную размерность вектора эмбеддинга: \n",
    "    - модуль `nn.Embedding` обучается\n",
    "\n",
    "  * Используйте одномерные свертки и пулинг (`nn.Conv1d`, `nn.MaxPool1d`)\n",
    "    - обратите внимание, что `nn.Conv1d` ожидает на вход трехмерный тензор размерности `(batch, embedding_dim, seq_len)`\n",
    "\n",
    "\n",
    "2.7 Измерить точность на тестовой выборке. Проверить работоспособность модели: придумать небольшой отзыв, прогнать его через модель и вывести номер предсказанного класса (сделать это для явно позитивного и явно негативного отзыва)\n",
    "* Целевое значение accuracy на валидации - 70+%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "positive_raw = pd.read_csv(\"./polarity/positive_reviews.csv\", header=None)\n",
    "negative_raw = pd.read_csv(\"./polarity/negative_reviews.csv\", header=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "positive_raw.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "negative_raw.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "positive_raw[\"state\"] = 1\n",
    "negative_raw[\"state\"] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "negative_raw"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "positive_raw"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_reviews = pd.concat([negative_raw, positive_raw], axis=0)\n",
    "all_reviews.columns = [\"review\", \"rating\"]\n",
    "all_reviews"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(all_reviews[\"review\"], all_reviews[\"rating\"], test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nltk.word_tokenize(all_reviews.review)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_reviews[\"review\"].flatten()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}